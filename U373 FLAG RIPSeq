#!/bin/bash

cd /N/slate/primukh

#copied all files from CMG server to mine

mkdir /Raw_data/Unzipped_files

#Since all my files had circular symbolic links, gzip command wasnt working. Used zcat instead which is similar to gzip except outpu file name without .gz extension needs to be mentioned
#Did individually for all 18 files

zcat U373-Control-338-RIP-4_S16_R1_001.fastq.gz > U373-Control-338-RIP-4_S16_R1_001.fastq

# Remember to activate your environment.

source activate rnaseq

# Unload system perl for compatability with entrez-direct.

module unload perl

# Assigning Variables.

ASSEMBLY='http://ftp.ensembl.org/pub/release-103/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz'

ANNOTATION='http://ftp.ensembl.org/pub/release-103/gtf/homo_sapiens/Homo_sapiens.GRCh38.103.gtf.gz'

################################
## Generate STAR Genome Index ##
################################

# Make a directory to store the genome files within your working directory.

mkdir -p genome

# Download and unpack the genome assembly.

curl $ASSEMBLY | gunzip > ./genome/assembly.fasta

# Download and unpack the genome annotation.

curl $ANNOTATION | gunzip > ./genome/annotation.gtf

# Create a directory to store the index.

mkdir -p genome/index

# Create the STAR genome index.
# --genomeSAindexNbases 12 was recommended by software.

STAR \
  --runThreadN 4 \
  --runMode genomeGenerate \
  --genomeDir genome/index \
  --genomeFastaFiles genome/assembly.fasta \
  --sjdbGTFfile genome/annotation.gtf \
  --genomeSAindexNbases 12
  
  ###########################
## Align Reads to Genome ##
###########################

# Create an output directory for aligned reads.

mkdir -p Results_FLAGRIP/aligned

# Align the reads.

FASTQ=$U373*

for FASTQ in ${FASTQ[@]}; do
  PREFIX=Results_FLAGRIP/aligned/$(basename $FASTQ .fastq)_
  STAR \
    --runThreadN 8 \
    --outFilterMultimapNmax 1 \
    --outFilterScoreMinOverLread .66 \
    --outFilterMismatchNmax 10 \
    --outFilterMismatchNoverLmax .3 \
    --runMode alignReads \
    --genomeDir genome/index \
    --readFilesIn $FASTQ \
    --outFileNamePrefix $PREFIX \
    --outSAMattributes All \
    --outSAMtype BAM SortedByCoordinate
done


# Indexing the BAM files.

BAMS=($(find ./Results_FLAGRIP/aligned -name "*\.bam"))

for BAM in ${BAMS[@]}; do
  samtools index $BAM
  done

 ####################
## Count Features ##
####################

# Create an output directory for read counts.

mkdir -p Results_FLAGRIP/counts

# Count reads.

BAMS=$(find ./Results_FLAGRIP/aligned -name "*\.bam")

featureCounts \
  -a genome/annotation.gtf \
  -o Results_FLAGRIP/counts/counts.tsv \
  -t gene \
  -g gene_id \
  --largestOverlap \
  --readExtension3 150 \
  --primary \
  -s 2 \
  -T 8 \
  ${BAMS}


#copy files to local desktop, perform on terminal
  scp primukh@carbonate.uits.iu.edu:/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/counts/counts.tsv.summary .
  scp primukh@carbonate.uits.iu.edu:/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/counts/counts.tsv .

########################################DESEq2################################

#Open RStudio on Thinlinc

library("tidyverse")

#Since BiocManager already available on Thinlinc RStudio, directly did the following. If not, write the following in separate lines.. 
# if (!requireNamespace("BiocManager", quietly = TRUE))
# install.packages("BiocManager")

#Installation not needed as DESEq2 was already present on my thinlinc R, but do this if on local R
#BiocManager::install("DESeq2")

#Load DESeq2
library("DESeq2")

#Load your data
countdata <- read.table("/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/counts/counts.tsv", header = TRUE, row.names = 1)

#To view the excel sheet on Rstudio
View(countdata)


#To remove all other columns except the ones containing the read counts i.e. after column 6. 
countdata <- countdata[,6:ncol(countdata)]

# After you type above command, you should see all the remaining columns disappear from the excel sheet that was visible after typing view(countdata). 
#This usually comes on the top of the screen and not on the console/termianl tab of RStudio
#Also, dont worry! The columns are  not removed from the original file. It's just removed from being analysed.

#To display names of all columns present in your file
colnames(countdata)

#To remove additional parts of the column names
colnames(countdata) <- gsub("..Results_FLAGRIP.aligned.","", colnames(countdata))

colnames(countdata) <- gsub("_S8_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S17_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S12_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S13_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S11_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S18_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S1_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S6_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S16_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S9_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S7_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S5_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S2_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S4_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S10_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S14_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S3_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))
colnames(countdata) <- gsub("_S15_R1_001_Aligned.sortedByCoord.out.bam","", colnames(countdata))

colnames(countdata) <- gsub("U373.Control.","", colnames(countdata))
colnames(countdata) <- gsub("U373.ADAR3.WT.","", colnames(countdata))
colnames(countdata) <- gsub("U373.ADAR3.R.Dom.","", colnames(countdata))

countdata <- as.matrix(countdata)

countdata <- countdata[,c("412.Input.1","412.Input.3","412.Input.4","338.Input.1","338.Input.3","338.Input.4")]

(condition <- factor(c(rep("b",3), rep("a",3))))

(coldata <- data.frame(row.names = colnames(countdata), condition))

dds <- DESeqDataSetFromMatrix( countData = countdata, colData = coldata, design=~condition)

#Deletes rows with 0 in all columns
keep = rowSums(counts(dds)) >=1

dds <- dds[keep,]

dds <- DESeq(dds)

res <- results(dds)

resdata <- merge(as.data.frame(res), as.data.frame(counts(dds,normalized=TRUE)), by="row.names", sort=FALSE)

names(resdata)[1] <- "Gene"

write.csv(resdata, file= "/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/U373_FLAGRIPSeq_05.11.23.csv")


#Secure copy files to your desktop
#Type this on your local desktop terminal

cd Desktop/U373FLAGRIPSeq

scp primukh@carbonate.uits.iu.edu:/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/U373_FLAGRIPSeq_05.11.23.csv .



#For PCA Plot, proceed with following: 
library("ggplot2")

vsd <- vst(dds, blind=FALSE)

pcaData <- plotPCA(vsd, intgroup=c("condition"), returnData=TRUE)

percentVar <- round(100 * attr(pcaData, "percentVar"))

ggplot(pcaData, aes(PC1, PC2, color=condition)) +
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) + 
  coord_fixed()
#Export the PCA plot and save as PDF (Right-bottom corner)

scp primukh@carbonate.uits.iu.edu:/N/u/primukh/Carbonate/Desktop/U373_FLAGRNASeq_338vs412_05.11.23 .

########################################ENSEMBL ID annotation################################
genelist <- read.csv("/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/U373_FLAGRIPSeq_05.11.23.csv", header = TRUE, row.names = 1)

colnames(genelist)

library("tidyr")
library("dplyr")
library("rlang")
library("magrittr")

#Needed to load biomart *facepalm*
install.packages("filelock") 

#load biomart package since running the ensemble command was giving an error. UseDataset command is available only through biomart. 

library(biomaRt, lib.loc = "/geode2/soft/hps/rhel7/bioconductor/3.14")

ensembl <- useDataset("hsapiens_gene_ensembl", mart = useMart("ensembl", host = "www.ensembl.org"))

annotations <- getBM(attributes=c("ensembl_gene_id", "hgnc_symbol", "description", "gene_biotype"), filters = "ensembl_gene_id", values = genelist$Gene, mart = ensembl)

final_genelist <- inner_join(genelist, annotations, by = c("Gene"="ensembl_gene_id"))

write.csv(final_genelist,file="/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/Annotated_U373_FLAGRNASeq_338vs412_05.11.23.csv")

#on local terminal

scp primukh@carbonate.uits.iu.edu:/N/slate/primukh/FLAGRIPSeq/Raw_data/Unzipped_files/Results_FLAGRIP/Annotated_U373_FLAGRNASeq_338vs412_05.11.23.csv .

